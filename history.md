# History

**Scriter 1.0**

* A static web application hosted on an AWS S3 bucket. 

* Custom scraping logic using urllib and Beautiful Soup

* Custom cleaning logic using Pandas and NLTK

* Basic hand-coded HTML and CSS

* Graphs generated with Matplotlib

My first attempt at a start-to-finish data pipeline. I had some
experience with data processing, but there were a lot of new
technologies to pick up. Web scraping, web dev, and AWS hosting were all
first time experiences. 


**Scriter 2.0**

* Converted to a single page application using vanilla JS

* Added Bootstrap 

* Various fixes to cleaning and scraping logic

For this iteration, I wanted to get a better handle on web dev
technology. My focus was on learning how Javascript integrates with
the rest of a web page. Bootstrap came up with enough frequency to
justify a detour.


**Scriter 3.0 (current)**

* Rewrite of scraping logic to use Scrapy

* Store results persistently in a database

* Host from a full web server

* Use a TF-IDF model instead of a unique frequency counter

